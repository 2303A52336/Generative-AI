{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOpD2Pdw+N+XoVrH8C9iN0A",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/2303A52336/Generative-AI/blob/main/Gen_AI(A8).ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dqfbCLDP0Pnw",
        "outputId": "3965a9b4-abb4-4048-85e9-9e25e1a919c7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/100\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/keras/src/layers/core/dense.py:87: UserWarning: Do not pass an `input_shape`/`input_dim` argument to a layer. When using Sequential models, prefer using an `Input(shape)` object as the first layer in the model instead.\n",
            "  super().__init__(activity_regularizer=activity_regularizer, **kwargs)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 18ms/step - accuracy: 0.0000e+00 - loss: 34.0368 - val_accuracy: 0.0000e+00 - val_loss: 33.2199\n",
            "Epoch 2/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.8926 - val_accuracy: 0.0000e+00 - val_loss: 33.2111\n",
            "Epoch 3/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5756 - val_accuracy: 0.0000e+00 - val_loss: 33.2021\n",
            "Epoch 4/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5456 - val_accuracy: 0.0000e+00 - val_loss: 33.1930\n",
            "Epoch 5/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5651 - val_accuracy: 0.0000e+00 - val_loss: 33.1838\n",
            "Epoch 6/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 33.1815 - val_accuracy: 0.0000e+00 - val_loss: 33.1744\n",
            "Epoch 7/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3046 - val_accuracy: 0.0000e+00 - val_loss: 33.1649\n",
            "Epoch 8/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4699 - val_accuracy: 0.0000e+00 - val_loss: 33.1553\n",
            "Epoch 9/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.6520 - val_accuracy: 0.0000e+00 - val_loss: 33.1455\n",
            "Epoch 10/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4877 - val_accuracy: 0.0000e+00 - val_loss: 33.1357\n",
            "Epoch 11/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.8832 - val_accuracy: 0.0000e+00 - val_loss: 33.1257\n",
            "Epoch 12/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4583 - val_accuracy: 0.0000e+00 - val_loss: 33.1156\n",
            "Epoch 13/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5847 - val_accuracy: 0.0000e+00 - val_loss: 33.1054\n",
            "Epoch 14/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5776 - val_accuracy: 0.0000e+00 - val_loss: 33.0951\n",
            "Epoch 15/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2594 - val_accuracy: 0.0000e+00 - val_loss: 33.0847\n",
            "Epoch 16/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2819 - val_accuracy: 0.0000e+00 - val_loss: 33.0742\n",
            "Epoch 17/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 32.9864 - val_accuracy: 0.0000e+00 - val_loss: 33.0637\n",
            "Epoch 18/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4767 - val_accuracy: 0.0000e+00 - val_loss: 33.0530\n",
            "Epoch 19/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5688 - val_accuracy: 0.0000e+00 - val_loss: 33.0423\n",
            "Epoch 20/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3986 - val_accuracy: 0.0000e+00 - val_loss: 33.0315\n",
            "Epoch 21/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.6848 - val_accuracy: 0.0000e+00 - val_loss: 33.0206\n",
            "Epoch 22/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.5523 - val_accuracy: 0.0000e+00 - val_loss: 33.0097\n",
            "Epoch 23/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3628 - val_accuracy: 0.0000e+00 - val_loss: 32.9986\n",
            "Epoch 24/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1166 - val_accuracy: 0.0000e+00 - val_loss: 32.9875\n",
            "Epoch 25/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0040 - val_accuracy: 0.0000e+00 - val_loss: 32.9764\n",
            "Epoch 26/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2252 - val_accuracy: 0.0000e+00 - val_loss: 32.9651\n",
            "Epoch 27/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 33.0818 - val_accuracy: 0.0000e+00 - val_loss: 32.9537\n",
            "Epoch 28/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3633 - val_accuracy: 0.0000e+00 - val_loss: 32.9423\n",
            "Epoch 29/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4025 - val_accuracy: 0.0000e+00 - val_loss: 32.9308\n",
            "Epoch 30/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0284 - val_accuracy: 0.0000e+00 - val_loss: 32.9193\n",
            "Epoch 31/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1006 - val_accuracy: 0.0000e+00 - val_loss: 32.9076\n",
            "Epoch 32/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.9901 - val_accuracy: 0.0000e+00 - val_loss: 32.8959\n",
            "Epoch 33/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3095 - val_accuracy: 0.0000e+00 - val_loss: 32.8842\n",
            "Epoch 34/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2033 - val_accuracy: 0.0000e+00 - val_loss: 32.8723\n",
            "Epoch 35/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4908 - val_accuracy: 0.0000e+00 - val_loss: 32.8604\n",
            "Epoch 36/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2454 - val_accuracy: 0.0000e+00 - val_loss: 32.8484\n",
            "Epoch 37/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.0000e+00 - loss: 32.9968 - val_accuracy: 0.0000e+00 - val_loss: 32.8364\n",
            "Epoch 38/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 33.0731 - val_accuracy: 0.0000e+00 - val_loss: 32.8243\n",
            "Epoch 39/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 33.4643 - val_accuracy: 0.0000e+00 - val_loss: 32.8121\n",
            "Epoch 40/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 33.1968 - val_accuracy: 0.0000e+00 - val_loss: 32.7998\n",
            "Epoch 41/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.0000e+00 - loss: 32.9497 - val_accuracy: 0.0000e+00 - val_loss: 32.7875\n",
            "Epoch 42/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 33.1157 - val_accuracy: 0.0000e+00 - val_loss: 32.7752\n",
            "Epoch 43/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 32.8248 - val_accuracy: 0.0000e+00 - val_loss: 32.7627\n",
            "Epoch 44/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.0000e+00 - loss: 32.8067 - val_accuracy: 0.0000e+00 - val_loss: 32.7503\n",
            "Epoch 45/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 32.9171 - val_accuracy: 0.0000e+00 - val_loss: 32.7377\n",
            "Epoch 46/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7873 - val_accuracy: 0.0000e+00 - val_loss: 32.7251\n",
            "Epoch 47/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1968 - val_accuracy: 0.0000e+00 - val_loss: 32.7125\n",
            "Epoch 48/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 32.7251 - val_accuracy: 0.0000e+00 - val_loss: 32.6998\n",
            "Epoch 49/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0282 - val_accuracy: 0.0000e+00 - val_loss: 32.6870\n",
            "Epoch 50/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.8895 - val_accuracy: 0.0000e+00 - val_loss: 32.6742\n",
            "Epoch 51/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 33.0617 - val_accuracy: 0.0000e+00 - val_loss: 32.6613\n",
            "Epoch 52/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.9216 - val_accuracy: 0.0000e+00 - val_loss: 32.6484\n",
            "Epoch 53/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7595 - val_accuracy: 0.0000e+00 - val_loss: 32.6355\n",
            "Epoch 54/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 32.9546 - val_accuracy: 0.0000e+00 - val_loss: 32.6225\n",
            "Epoch 55/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.4478 - val_accuracy: 0.0000e+00 - val_loss: 32.6094\n",
            "Epoch 56/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.3247 - val_accuracy: 0.0000e+00 - val_loss: 32.5962\n",
            "Epoch 57/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 33.1939 - val_accuracy: 0.0000e+00 - val_loss: 32.5831\n",
            "Epoch 58/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 8ms/step - accuracy: 0.0000e+00 - loss: 32.3359 - val_accuracy: 0.0000e+00 - val_loss: 32.5699\n",
            "Epoch 59/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.6508 - val_accuracy: 0.0000e+00 - val_loss: 32.5566\n",
            "Epoch 60/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1053 - val_accuracy: 0.0000e+00 - val_loss: 32.5434\n",
            "Epoch 61/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1442 - val_accuracy: 0.0000e+00 - val_loss: 32.5300\n",
            "Epoch 62/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.8598 - val_accuracy: 0.0000e+00 - val_loss: 32.5165\n",
            "Epoch 63/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2670 - val_accuracy: 0.0000e+00 - val_loss: 32.5030\n",
            "Epoch 64/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7083 - val_accuracy: 0.0000e+00 - val_loss: 32.4895\n",
            "Epoch 65/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0558 - val_accuracy: 0.0000e+00 - val_loss: 32.4760\n",
            "Epoch 66/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2112 - val_accuracy: 0.0000e+00 - val_loss: 32.4624\n",
            "Epoch 67/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7117 - val_accuracy: 0.0000e+00 - val_loss: 32.4488\n",
            "Epoch 68/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.2007 - val_accuracy: 0.0000e+00 - val_loss: 32.4351\n",
            "Epoch 69/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4115 - val_accuracy: 0.0000e+00 - val_loss: 32.4214\n",
            "Epoch 70/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.5018 - val_accuracy: 0.0000e+00 - val_loss: 32.4077\n",
            "Epoch 71/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 32.5479 - val_accuracy: 0.0000e+00 - val_loss: 32.3939\n",
            "Epoch 72/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.1580 - val_accuracy: 0.0000e+00 - val_loss: 32.3801\n",
            "Epoch 73/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7754 - val_accuracy: 0.0000e+00 - val_loss: 32.3662\n",
            "Epoch 74/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.6264 - val_accuracy: 0.0000e+00 - val_loss: 32.3523\n",
            "Epoch 75/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.8008 - val_accuracy: 0.0000e+00 - val_loss: 32.3383\n",
            "Epoch 76/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 32.4343 - val_accuracy: 0.0000e+00 - val_loss: 32.3244\n",
            "Epoch 77/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4701 - val_accuracy: 0.0000e+00 - val_loss: 32.3103\n",
            "Epoch 78/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.5590 - val_accuracy: 0.0000e+00 - val_loss: 32.2962\n",
            "Epoch 79/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.0000e+00 - loss: 32.6091 - val_accuracy: 0.0000e+00 - val_loss: 32.2821\n",
            "Epoch 80/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7765 - val_accuracy: 0.0000e+00 - val_loss: 32.2679\n",
            "Epoch 81/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.7644 - val_accuracy: 0.0000e+00 - val_loss: 32.2537\n",
            "Epoch 82/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.6570 - val_accuracy: 0.0000e+00 - val_loss: 32.2395\n",
            "Epoch 83/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4504 - val_accuracy: 0.0000e+00 - val_loss: 32.2253\n",
            "Epoch 84/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4735 - val_accuracy: 0.0000e+00 - val_loss: 32.2111\n",
            "Epoch 85/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 32.3373 - val_accuracy: 0.0000e+00 - val_loss: 32.1969\n",
            "Epoch 86/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4599 - val_accuracy: 0.0000e+00 - val_loss: 32.1826\n",
            "Epoch 87/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4910 - val_accuracy: 0.0000e+00 - val_loss: 32.1683\n",
            "Epoch 88/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.5589 - val_accuracy: 0.0000e+00 - val_loss: 32.1540\n",
            "Epoch 89/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0591 - val_accuracy: 0.0000e+00 - val_loss: 32.1397\n",
            "Epoch 90/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.5417 - val_accuracy: 0.0000e+00 - val_loss: 32.1253\n",
            "Epoch 91/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.3260 - val_accuracy: 0.0000e+00 - val_loss: 32.1108\n",
            "Epoch 92/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4599 - val_accuracy: 0.0000e+00 - val_loss: 32.0963\n",
            "Epoch 93/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 7ms/step - accuracy: 0.0000e+00 - loss: 32.3093 - val_accuracy: 0.0000e+00 - val_loss: 32.0818\n",
            "Epoch 94/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4167 - val_accuracy: 0.0000e+00 - val_loss: 32.0672\n",
            "Epoch 95/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 33.0572 - val_accuracy: 0.0000e+00 - val_loss: 32.0525\n",
            "Epoch 96/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.2326 - val_accuracy: 0.0000e+00 - val_loss: 32.0378\n",
            "Epoch 97/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.6255 - val_accuracy: 0.0000e+00 - val_loss: 32.0231\n",
            "Epoch 98/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.1324 - val_accuracy: 0.0000e+00 - val_loss: 32.0083\n",
            "Epoch 99/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.2929 - val_accuracy: 0.0000e+00 - val_loss: 31.9935\n",
            "Epoch 100/100\n",
            "\u001b[1m16/16\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 6ms/step - accuracy: 0.0000e+00 - loss: 32.4051 - val_accuracy: 0.0000e+00 - val_loss: 31.9786\n"
          ]
        }
      ],
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import StandardScaler\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense\n",
        "from sklearn.metrics import confusion_matrix, classification_report\n",
        "\n",
        "# Load dataset\n",
        "data = pd.read_csv('winequality-red.csv')\n",
        "X = data.drop('quality', axis=1)\n",
        "y = data['quality']\n",
        "\n",
        "# Normalize the input data\n",
        "scaler = StandardScaler()\n",
        "X_scaled = scaler.fit_transform(X)\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(X_scaled, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the ANN model\n",
        "model = Sequential([\n",
        "    Dense(16, activation='relu', input_dim=X_train.shape[1]),\n",
        "    Dense(20, activation='relu'),\n",
        "    Dense(25, activation='relu'),\n",
        "    Dense(10, activation='relu'),\n",
        "    Dense(1, activation='linear')  # Linear activation for regression\n",
        "])\n",
        "\n",
        "# Compile the model\n",
        "model.compile(optimizer='adadelta', loss='mean_squared_error', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=64, validation_split=0.2)\n",
        "\n",
        "# Save the model\n",
        "model.save('winequality-red.keras')"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Make predictions\n",
        "y_pred = model.predict(X_test)\n",
        "y_pred_classes = [round(pred[0]) for pred in y_pred]  # Adjust as needed for classification\n",
        "\n",
        "# Confusion matrix and classification report\n",
        "conf_matrix = confusion_matrix(y_test, y_pred_classes)\n",
        "print(\"Confusion Matrix:\\n\", conf_matrix)\n",
        "print(\"Classification Report:\\n\", classification_report(y_test, y_pred_classes))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PmVaOekz1MHP",
        "outputId": "b7beadd2-bdcf-46a6-ed6c-edaa2e8d46ed"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 7ms/step  \n",
            "Confusion Matrix:\n",
            " [[  0   0   0   0   0   0   0   0]\n",
            " [  0   0   0   0   0   0   0   0]\n",
            " [  1   0   0   0   0   0   0   0]\n",
            " [ 10   0   0   0   0   0   0   0]\n",
            " [130   0   0   0   0   0   0   0]\n",
            " [127   5   0   0   0   0   0   0]\n",
            " [ 41   1   0   0   0   0   0   0]\n",
            " [  5   0   0   0   0   0   0   0]]\n",
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.00      0.00      0.00       0.0\n",
            "           1       0.00      0.00      0.00       0.0\n",
            "           3       0.00      0.00      0.00       1.0\n",
            "           4       0.00      0.00      0.00      10.0\n",
            "           5       0.00      0.00      0.00     130.0\n",
            "           6       0.00      0.00      0.00     132.0\n",
            "           7       0.00      0.00      0.00      42.0\n",
            "           8       0.00      0.00      0.00       5.0\n",
            "\n",
            "    accuracy                           0.00     320.0\n",
            "   macro avg       0.00      0.00      0.00     320.0\n",
            "weighted avg       0.00      0.00      0.00     320.0\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_classification.py:1565: UndefinedMetricWarning: Recall is ill-defined and being set to 0.0 in labels with no true samples. Use `zero_division` parameter to control this behavior.\n",
            "  _warn_prf(average, modifier, f\"{metric.capitalize()} is\", len(result))\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras.models import load_model\n",
        "\n",
        "# Load the saved model\n",
        "# Changed file name to match the name used when saving the model\n",
        "loaded_model = load_model('winequality-red.keras')\n",
        "# Predict new inputs\n",
        "def predict_new_quality(input_features):\n",
        "    scaled_features = scaler.transform([input_features])\n",
        "    prediction = loaded_model.predict(scaled_features)\n",
        "    return prediction[0][0]  # Adjust as needed"
      ],
      "metadata": {
        "id": "qVhQ2ru91Rv1"
      },
      "execution_count": 7,
      "outputs": []
    }
  ]
}